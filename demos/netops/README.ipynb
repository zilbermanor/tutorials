{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netops\n",
    "## Predictive Infrastructure Monitoring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**   \n",
    "\n",
    "The netops demo demonstrates predictive infrastructure monitoring: the application builds, trains, and deploys a machine-learning model for analyzing and predicting failure in network devices as part of a network operations (NetOps) flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This full system demo is used to showcase multiple ways to build machine learning pipelines:\n",
    "\n",
    "- [**Jupyter notebook**](#jupyter-dask): Using jupyter as our IDE: generating the data, exploring, training a model, deploying a nuclio function for inference and a grafana dashboard to monitor. <br>\n",
    "Note that for running the code at slace we are using Daks. Dask is an open source library for running distributed python \n",
    "\n",
    "- [**Nuclio**](#nuclio): Leveraging Nuclio (servless function framework) for deploying the model from Jupyter as a nuclio function that can run in a serving layer\n",
    "\n",
    "Note that under the pipelines directory we've created the same demo where each step can be deployed and run as a Nuclio function <br>\n",
    "By doing that users can build an automated pipeline and use those functions as components in the pipeline"   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo structure\n",
    "The demo is comprised of four main parts:  \n",
    "\n",
    "**Generator**:  \n",
    "\\[[Jupyter-Dask](01-generator.ipynb) | [Nuclio](pipelines/nuclio-generator.ipynb)]  \n",
    "\n",
    "Using our open source [deployment generator](https://github.com/zilbermanor/deployment_generator/tree/master/v3io_generator) (Which you can pip install [here](https://test.pypi.org/manage/project/v3io-generator/releases/)) we create a network deployment (e.g. with default names for Company, Data center, Device).  \n",
    "We then add our metrics via [metrics configuration](configurations/metrics_configuration.yaml). (Defaults to CPU Utilization, Latency, Throughput, Packet loss).   \n",
    "\n",
    "The generator can create both normal device metrics as defined by the Yaml, and error scenarios that cascade through the metrics until the device reaches a critical failure.\n",
    "\n",
    "To see the devices behaviour you can look at the **[Exploration](02-explore.ipynb)** notebook.\n",
    "\n",
    "**Data Preprocessing**:  \n",
    "\\[[Jupyter-Dask](01-generator.ipynb) | [Nuclio](pipelines/nuclio-data-preperations.ipynb)]  \n",
    "\n",
    "Turning the device's metrics stream to a feature vector using aggregations from multiple timespans (Current, Minutely, Hourly)  \n",
    "\n",
    "**Training**:  \n",
    "\\[[Jupyter-Dask](03-training.ipynb) | [Nuclio](pipelines/nuclio-training.ipynb)]  \n",
    "\n",
    "Using the feature vectors from the previous steps, and the **is_error** metrics given by the generator, train a ML model (Spans from scikit based to XGBoost & TF).  \n",
    "The model is then saved to a file for future usage.  \n",
    "\n",
    "**Inference**:  \n",
    "\\[[Jupyter-Dask](04-infer.ipynb) | [Nuclio](pipelines/nuclio-inference.ipynb)] \n",
    "\n",
    "Create a Nuclio function based on the model file from the previous step and the feature vectors created by the Preprocessing stage <br>\n",
    "In this notebook we demonstrate how to take a model written in Python and easily convert it to a serverless function\n",
    "This function can run in a serving layer as part of a production pipeline.The goal for this model predicts if a device is about to fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter-Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [Generator](01-generator.ipynb)\n",
    " - [Exploration](02-explore.ipynb)\n",
    " - [Training](03-training.ipynb)\n",
    " - [Inference](04-infer.ipynb)\n",
    " - [Dashboard](05-grafana.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [Generator](pipelines/nuclio-generator.ipynb)\n",
    " - [PreProcessing](pipelines/nuclio-data-preperations.ipynb)\n",
    " - [Training](pipelines/nuclio-training.ipynb)\n",
    " - [Inference](pipelines/nuclio-inference.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
