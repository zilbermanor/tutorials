{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclio - Generator function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560956279\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "# Set initial timestamp as 7 days ago\n",
    "os.environ['INITIAL_TS'] = str(int((datetime.datetime.now()-datetime.timedelta(days=1)).timestamp()))\n",
    "print(os.getenv('INITIAL_TS', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.triggers.secs.kind to 'cron'\n",
      "%nuclio: setting spec.triggers.secs.attributes.interval to '10s'\n",
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config \n",
    "\n",
    "# Trigger\n",
    "spec.triggers.secs.kind = \"cron\"\n",
    "spec.triggers.secs.attributes.interval = \"10s\"\n",
    "\n",
    "# Base image\n",
    "spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configuration file for function pulling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/v3io/bigdata/netops_configurations’: File exists\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "os.environ['local_configurations_path'] = os.path.join(os.path.dirname(os.getcwd()), 'configurations', 'metrics_configuration.yaml')\n",
    "os.environ['shared_configurations_path'] = os.path.join('/', 'v3io', 'bigdata', 'netops_configurations')\n",
    "os.environ['webapi_configuration_path'] = os.path.join('/', 'bigdata', 'netops_configurations', 'metrics_configuration.yaml')\n",
    "os.environ['function_configuration_dir'] = os.path.join('/', 'configurations')\n",
    "\n",
    "!mkdir ${shared_configurations_path}\n",
    "!cp ${local_configurations_path} -t ${shared_configurations_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'METRICS_CONFIGURATION_FILEPATH' environment variable\n"
     ]
    }
   ],
   "source": [
    "%nuclio env -c METRICS_CONFIGURATION_FILEPATH=/configurations/metrics_configuration.yaml\n",
    "%nuclio env -l METRICS_CONFIGURATION_FILEPATH=../configurations/metrics_configuration.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "# Pull configuration file to function\n",
    "apt-get update && apt-get install -y wget\n",
    "mkdir -p ${function_configuration_dir}\n",
    "wget -O ${METRICS_CONFIGURATION_FILEPATH} --header \"x-v3io-session-key: ${V3IO_ACCESS_KEY}\" http://${V3IO_WEBAPI_SERVICE_HOST}:8081${webapi_configuration_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /User/.pythonlibs/lib/python3.6/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /conda/lib/python3.6/site-packages (from pyarrow) (1.16.4)\n",
      "Requirement already satisfied: six>=1.0.0 in /conda/lib/python3.6/site-packages (from pyarrow) (1.12.0)\n",
      "Collecting pyyaml\n",
      "\u001b[31mnuclio-jupyter 0.7.2 has requirement tornado<6,>=5, but you'll have tornado 6.0.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyyaml\n",
      "  Found existing installation: PyYAML 5.1\n",
      "\u001b[31mCannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "Requirement already satisfied: pandas in /conda/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /conda/lib/python3.6/site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: pytimeparse in /User/.pythonlibs/lib/python3.6/site-packages (1.1.8)\n",
      "Requirement already up-to-date: v3io_frames in /User/.pythonlibs/lib/python3.6/site-packages (0.5.6)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos>=1.5.3 in /conda/lib/python3.6/site-packages (from v3io_frames) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.1 in /conda/lib/python3.6/site-packages (from v3io_frames) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas==0.23.* in /conda/lib/python3.6/site-packages (from v3io_frames) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio-tools>=1.16.0 in /conda/lib/python3.6/site-packages (from v3io_frames) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /conda/lib/python3.6/site-packages (from googleapis-common-protos>=1.5.3->v3io_frames) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /conda/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /conda/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /conda/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /conda/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.21.1 in /conda/lib/python3.6/site-packages (from grpcio-tools>=1.16.0->v3io_frames) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9 in /conda/lib/python3.6/site-packages (from protobuf>=3.6.0->googleapis-common-protos>=1.5.3->v3io_frames) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /conda/lib/python3.6/site-packages (from protobuf>=3.6.0->googleapis-common-protos>=1.5.3->v3io_frames) (41.0.1)\n",
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Requirement already satisfied: v3io-generator in /User/.pythonlibs/lib/python3.6/site-packages (0.0.27.dev0)\n",
      "Requirement already satisfied: faker in /User/.pythonlibs/lib/python3.6/site-packages (1.0.7)\n",
      "Requirement already satisfied: text-unidecode==1.2 in /User/.pythonlibs/lib/python3.6/site-packages (from faker) (1.2)\n",
      "Requirement already satisfied: six>=1.10 in /conda/lib/python3.6/site-packages (from faker) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /conda/lib/python3.6/site-packages (from faker) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "%%nuclio cmd\n",
    "\n",
    "# Utils\n",
    "pip install pyarrow\n",
    "pip install pyyaml --upgrade\n",
    "pip install pandas\n",
    "pip install pytimeparse\n",
    "\n",
    "# Igz DB\n",
    "pip install v3io_frames --upgrade\n",
    "\n",
    "# Function\n",
    "pip install -i https://test.pypi.org/simple/ v3io-generator\n",
    "pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'V3IO_FRAMESD' environment variable\n",
      "%nuclio: setting 'V3IO_USERNAME' environment variable\n",
      "%nuclio: setting 'V3IO_ACCESS_KEY' environment variable\n",
      "%nuclio: setting 'SAVE_DEPLOYMENT' environment variable\n",
      "%nuclio: setting 'DEPLOYMENT_TABLE' environment variable\n",
      "%nuclio: setting '# SAVE_TO' environment variable\n",
      "%nuclio: setting 'SAVE_TO' environment variable\n",
      "%nuclio: setting 'INITIAL_TIMESTAMP' environment variable\n",
      "%nuclio: setting 'SECS_TO_GENERATE' environment variable\n",
      "%nuclio: setting 'SAVE_TO_TSDB' environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n"
     ]
    }
   ],
   "source": [
    "%%nuclio env\n",
    "\n",
    "# DB Config\n",
    "V3IO_FRAMESD=${V3IO_FRAMESD}\n",
    "V3IO_USERNAME=${V3IO_USERNAME}\n",
    "V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "\n",
    "# Deployment\n",
    "SAVE_DEPLOYMENT=1\n",
    "DEPLOYMENT_TABLE=netops_devices\n",
    "\n",
    "# Metrics\n",
    "\n",
    "# Parquet\n",
    "# SAVE_TO=/v3io/bigdata/netops_metrics_parquet\n",
    "SAVE_TO=netops_metrics\n",
    "\n",
    "INITIAL_TIMESTAMP=${INITIAL_TS}\n",
    "SECS_TO_GENERATE=10\n",
    "\n",
    "# Save as\n",
    "SAVE_TO_TSDB=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # Already imported earlier\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# DB Connection\n",
    "import v3io_frames as v3f\n",
    "\n",
    "# Data generator\n",
    "from v3io_generator import metrics_generator, deployment_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_deployment():\n",
    "    print('creating deployment')\n",
    "    # Create meta-data factory\n",
    "    dep_gen = deployment_generator.deployment_generator()\n",
    "    faker=dep_gen.get_faker()\n",
    "\n",
    "    # Design meta-data\n",
    "    dep_gen.add_level(name='company',number=2,level_type=faker.company)\n",
    "    dep_gen.add_level('data_center',number=2,level_type=faker.street_name)\n",
    "    dep_gen.add_level('device',number=2,level_type=faker.msisdn)\n",
    "\n",
    "    # Create meta-data\n",
    "    deployment_df = dep_gen.generate_deployment()\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_deployment_exist(path):\n",
    "    # Checking shared path for the devices table\n",
    "    return os.path.exists(f'/v3io/bigdata/{path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_deployment_from_kv(client, path):\n",
    "    print(f'Retrieving deployment from {path}')\n",
    "    context.logger.debug(f'Retrieving deployment from {path}')\n",
    "    # Read the devices table from our KV store\n",
    "    deployment_df = client.read(backend='kv', table=path)\n",
    "    \n",
    "    # Reset index to column\n",
    "    deployment_df.index.name = 'device'\n",
    "    deployment_df = deployment_df.reset_index()\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_deployment_to_kv(path, df, client=v3f.Client('framesd:8081')):\n",
    "    # Save deployment to our KV store\n",
    "    client.write(backend='kv', table='netops_devices',dfs=df, index_cols=['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_deployment(path, save_to_cloud=False, client=None):\n",
    "    if client and _is_deployment_exist(path):\n",
    "        # Get deployment from KV\n",
    "        deployment_df = _get_deployment_from_kv(client, path)\n",
    "    else:\n",
    "        # Create deployment\n",
    "        deployment_df = _create_deployment()\n",
    "        \n",
    "        if client and save_to_cloud:\n",
    "            _save_deployment_to_kv(path, deployment_df, client)\n",
    "\n",
    "    return deployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_indexes(df):\n",
    "    df = df.set_index(['timestamp', 'company', 'data_center', 'device'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_tsdb(context, metrics: pd.DataFrame):\n",
    "    print('Saving metrics to TSDB')\n",
    "    \n",
    "    context.v3f.write('tsdb', context.metrics_table, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_parquet(context, metrics):\n",
    "    print('Saving metrics to Parquet')\n",
    "    df = pd.concat(itertools.chain(metrics))\n",
    "    \n",
    "    # Need to fix timestamps from ns to ms if we write to parquet\n",
    "    df = df.reset_index()\n",
    "    df['timestamp'] = df.loc[:, 'timestamp'].astype('datetime64[ms]')\n",
    "    \n",
    "    # Fix indexes\n",
    "    df = set_indexes(df)\n",
    "    \n",
    "    # Save parquet\n",
    "    first_timestamp = df.index[0][0].strftime('%Y%m%dT%H%M%S')\n",
    "    last_timestamp = df.index[-1][0].strftime('%Y%m%dT%H%M%S')\n",
    "    filename = first_timestamp + '-' + last_timestamp + '.parquet'\n",
    "    print(filename)\n",
    "    filepath = os.path.join(context.metrics_table, filename)\n",
    "    print(filepath)\n",
    "    with open(filepath, 'wb+') as f:\n",
    "        df.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_deployment_initialized(context):\n",
    "    return hasattr(context, 'metric_generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    \n",
    "    # Get saving configuration\n",
    "    save_to_tsdb = (int(os.getenv('SAVE_TO_TSDB', 1)) == 1)\n",
    "    \n",
    "    # Set metrics table\n",
    "    metrics_table = os.getenv('SAVE_TO', 'netops_metrics')\n",
    "    setattr(context, 'metrics_table', metrics_table) \n",
    "\n",
    "    # TSDB Based demo\n",
    "    if save_to_tsdb:\n",
    "        context.logger.debug('Saving to TSDB')\n",
    "        # Create our DB client\n",
    "        client = v3f.Client(address='framesd:8081', container='bigdata')\n",
    "        \n",
    "        # Create TSDB table if needed\n",
    "        client.create('tsdb', metrics_table, attrs={'rate': '1/s'}, if_exists=1)\n",
    "        \n",
    "        # Set saving function\n",
    "        setattr(context, 'write', save_metrics_to_tsdb)\n",
    "    \n",
    "    # Parquet based demo\n",
    "    else:\n",
    "        context.logger.debug('Saving to Parquet')\n",
    "        # Set empty client for verification purposes\n",
    "        client = None\n",
    "          \n",
    "        # Create saving directory\n",
    "        filepath = os.path.join(metrics_table)\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "        \n",
    "        # Set saving function\n",
    "        setattr(context, 'write', save_metrics_to_parquet)\n",
    "    \n",
    "          \n",
    "    # Set batch endtime\n",
    "    secs_to_generate = os.getenv('SECS_TO_GENERATE', 10)\n",
    "    setattr(context, 'secs_to_generate', secs_to_generate)\n",
    "    \n",
    "     \n",
    "    \n",
    "    # Generate or create deployment\n",
    "    deployment_df = get_or_create_deployment(os.environ['DEPLOYMENT_TABLE'], os.environ['SAVE_DEPLOYMENT'], client)\n",
    "    \n",
    "    deployment_df['cpu_utilization'] = 70\n",
    "    deployment_df['latency'] = 0\n",
    "    deployment_df['packet_loss'] = 0\n",
    "    deployment_df['throughput'] = 290\n",
    "    deployment_df.head()\n",
    "    \n",
    "    # Get metrics configuration\n",
    "    with open(os.getenv('METRICS_CONFIGURATION_FILEPATH', '/configurations/metrics_configuration.yaml'), 'r') as f:\n",
    "        metrics_configuration = yaml.load(f)\n",
    "        \n",
    "    # Create metrics generator\n",
    "    initial_timestamp = int(os.getenv('INITIAL_TIMESTAMP', time.time()))\n",
    "    met_gen = metrics_generator.Generator_df(metrics_configuration, \n",
    "                                             user_hierarchy=deployment_df, \n",
    "                                             initial_timestamp=initial_timestamp)\n",
    "    setattr(context, 'metric_generator', met_gen)\n",
    "    \n",
    "    # Set client\n",
    "    setattr(context, 'v3f', client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "       \n",
    "    # Create metrics generator based on YAML configuration and deployment\n",
    "    metrics = context.metric_generator.generate_range(start_time=datetime.datetime.now(),\n",
    "                                     end_time=datetime.datetime.now()+datetime.timedelta(seconds=int(context.secs_to_generate)),\n",
    "                                     as_df=True,\n",
    "                                     as_iterator=True)\n",
    "    \n",
    "    # Save Generated metrics\n",
    "    context.write(context, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving deployment from netops_devices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/ipykernel_launcher.py:57: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving metrics to TSDB\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "init_context(context)\n",
    "event = nuclio.Event(body='')\n",
    "output = handler(context, event)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nuclio.deploy] 2019-06-20 06:05:47,211 (info) Building processor image\n",
      "[nuclio.deploy] 2019-06-20 06:05:53,269 (info) Pushing image\n",
      "[nuclio.deploy] 2019-06-20 06:05:53,270 (info) Build complete\n",
      "[nuclio.deploy] 2019-06-20 06:05:57,365 (info) Function deploy complete\n",
      "[nuclio.deploy] 2019-06-20 06:05:57,370 done updating generator, function address: 18.185.111.133:31908\n",
      "%nuclio: function deployed\n"
     ]
    }
   ],
   "source": [
    "%nuclio deploy -p netops -n generator -c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
