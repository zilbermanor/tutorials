{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location based recommendation - Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach a fully working system we need to extract features from the data and create product embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configurations\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data/')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models/')\n",
    "RANDOM_STATE = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIR=/User/demos/location-based-recommendation/data/\n",
      "env: MODELS_DIR=/User/demos/location-based-recommendation/models/\n",
      "env: RANDOM_STATE=2017\n"
     ]
    }
   ],
   "source": [
    "%env DATA_DIR={DATA_DIR}\n",
    "%env MODELS_DIR={MODELS_DIR}\n",
    "%env RANDOM_STATE={RANDOM_STATE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles_raw = pd.read_csv(DATA_DIR + 'aisles.csv', dtype={'aisle_id': np.uint8,\n",
    "                                                         'aisle': 'category'})\n",
    "\n",
    "departments_raw = pd.read_csv(DATA_DIR + 'departments.csv', dtype={'department_id': np.uint8,\n",
    "                                                                   'department': 'category'})\n",
    "\n",
    "order_prior_raw = pd.read_csv(DATA_DIR + 'order_products__prior.csv', dtype={'order_id': np.uint32,\n",
    "                                                                             'product_id': np.uint16,\n",
    "                                                                             'add_to_cart_order': np.uint8,\n",
    "                                                                             'reordered': bool})\n",
    "\n",
    "order_train_raw = pd.read_csv(DATA_DIR + 'order_products__train.csv', dtype={'order_id': np.uint32,\n",
    "                                                                             'product_id': np.uint16,\n",
    "                                                                             'add_to_cart_order': np.uint8,\n",
    "                                                                             'reordered': bool})\n",
    "\n",
    "orders_raw = pd.read_csv(DATA_DIR + 'orders.csv', dtype={'order_id': np.uint32,\n",
    "                                                         'user_id': np.uint32,\n",
    "                                                         'eval_set': 'category',\n",
    "                                                         'order_number': np.uint8,\n",
    "                                                         'order_dow': np.uint8,\n",
    "                                                         'order_hour_of_day': np.uint8})\n",
    "\n",
    "products_raw = pd.read_csv(DATA_DIR + 'products.csv', dtype={'product_id': np.uint16,\n",
    "                                                             'aisle_id': np.uint8,\n",
    "                                                             'department_id': np.uint8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "### Create previous products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders_raw.loc[orders_raw.eval_set == 'prior', :]\n",
    "orders_user = orders[['order_id', 'user_id']]\n",
    "labels = pd.merge(order_prior_raw, orders_user, on='order_id')\n",
    "labels = labels.loc[:, ['user_id', 'product_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_pickle(DATA_DIR + 'previous_products.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate chunks (folds) for later CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FOLDS=5\n"
     ]
    }
   ],
   "source": [
    "%env FOLDS={FOLDS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders_raw.loc[(orders_raw.eval_set == 'train') | (orders_raw.eval_set == 'test'), :]\n",
    "labels_2 = pd.merge(labels, orders[['order_id', 'user_id', 'eval_set']], on='user_id').drop(['user_id'], axis=1)\n",
    "\n",
    "order_train = order_train_raw.drop(['add_to_cart_order'], axis=1)\n",
    "orders = np.unique(labels_2.order_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206209,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'product_id', 'reordered', 'eval_set'], dtype='object')\n",
      "(2668945, 4)\n",
      "Index(['order_id', 'product_id', 'reordered', 'eval_set'], dtype='object')\n",
      "(2654629, 4)\n",
      "Index(['order_id', 'product_id', 'reordered', 'eval_set'], dtype='object')\n",
      "(2653526, 4)\n",
      "Index(['order_id', 'product_id', 'reordered', 'eval_set'], dtype='object')\n",
      "(2653889, 4)\n",
      "Index(['order_id', 'product_id', 'reordered', 'eval_set'], dtype='object')\n",
      "(2676766, 4)\n"
     ]
    }
   ],
   "source": [
    "size = orders.shape[0] // FOLDS\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    current = orders[fold * size:(fold + 1) * size]\n",
    "    current = labels_2.loc[np.in1d(labels_2.order_id, current), :]\n",
    "    current = pd.merge(order_train, current, on=['order_id', 'product_id'], how='right')\n",
    "    current.reordered.fillna(False, inplace=True)\n",
    "    print(current.columns)\n",
    "    print(current.shape)\n",
    "\n",
    "    current.to_pickle(DATA_DIR + 'chunk_{}.pkl'.format(fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Orders CumSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prior = order_prior_raw\n",
    "orders = orders_raw\n",
    "products = products_raw\n",
    "user_product = labels\n",
    "labels = labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_products_columns:\n",
      "Index(['order_id', 'product_id', 'eval_set', 'user_id', 'order_number',\n",
      "       'days_since_prior_order_comsum'],\n",
      "      dtype='object')\n",
      "user_product_columns:\n",
      "Index(['user_id', 'product_id'], dtype='object')\n",
      "Summing order distances\n",
      "Adding aggregations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "order_comsum = orders[['user_id', 'order_number', 'days_since_prior_order']].groupby(['user_id', 'order_number']) \\\n",
    "    ['days_since_prior_order'].sum().groupby(level=[0]).cumsum().reset_index().rename(\n",
    "    columns={'days_since_prior_order': 'days_since_prior_order_comsum'})\n",
    "\n",
    "order_comsum.to_pickle(DATA_DIR + 'orders_comsum.pkl')\n",
    "\n",
    "order_comsum = pd.merge(order_comsum, orders, on=['user_id', 'order_number'])[\n",
    "    ['user_id', 'order_number', 'days_since_prior_order_comsum', 'order_id']]\n",
    "\n",
    "order_product = pd.merge(order_prior, orders, on='order_id')[['order_id', 'product_id', 'eval_set']]\n",
    "order_product_train_test = labels[['order_id', 'product_id', 'eval_set']]\n",
    "\n",
    "order_product = pd.concat([order_product, order_product_train_test])\n",
    "\n",
    "order_product = pd.merge(order_product, order_comsum, on='order_id')\n",
    "\n",
    "print(f'order_products_columns:\\n{order_product.columns}')\n",
    "print(f'user_product_columns:\\n{user_product.columns}')\n",
    "\n",
    "order_product = pd.merge(order_product, user_product, on=['user_id',\n",
    "                                                          'product_id'])  # user_id, order_id, product_id, eval_set, order_id, Days_since_prior (comsum)\n",
    "\n",
    "print('Summing order distances')\n",
    "temp = order_product.groupby(['user_id', 'product_id', 'order_number'])[\n",
    "    'days_since_prior_order_comsum'].sum().groupby(level=[0, 1]).apply(lambda x: np.diff(np.nan_to_num(x)))\n",
    "temp = temp.to_frame('periods').reset_index()\n",
    "\n",
    "# temp.to_pickle(DATA_DIR + 'product_period.pkl')\n",
    "\n",
    "print('Adding aggregations')\n",
    "aggregated = temp.copy()\n",
    "aggregated['last'] = aggregated.periods.apply(lambda x: x[-1])\n",
    "aggregated['prev1'] = aggregated.periods.apply(lambda x: x[-2] if len(x) > 1 else np.nan)\n",
    "aggregated['prev2'] = aggregated.periods.apply(lambda x: x[-3] if len(x) > 2 else np.nan)\n",
    "aggregated['median'] = aggregated.periods.apply(lambda x: np.median(x[:-1]))\n",
    "aggregated['mean'] = aggregated.periods.apply(lambda x: np.mean(x[:-1]))\n",
    "aggregated.drop('periods', axis=1, inplace=True)\n",
    "\n",
    "aggregated.to_pickle(DATA_DIR + 'product_periods_stat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate user-product rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_id', 'reordered'], dtype='object')\n",
      "Index(['user_id', 'department_id', 'dep_products', 'dep_reordered'], dtype='object')\n",
      "Index(['product_id', 'reordered'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "orders_products = pd.merge(orders, order_prior, on=\"order_id\")\n",
    "\n",
    "orders_products_products = pd.merge(orders_products, products[['product_id', 'department_id', 'aisle_id']],\n",
    "                                    on='product_id')\n",
    "\n",
    "user_dep_stat = orders_products_products.groupby(['user_id', 'department_id']).agg(\n",
    "    {'product_id': lambda x: x.nunique(),\n",
    "     'reordered': 'sum'\n",
    "     })\n",
    "print(user_dep_stat.columns)\n",
    "user_dep_stat.rename(columns={'product_id': 'dep_products',\n",
    "                              'reordered': 'dep_reordered'}, inplace=True)\n",
    "user_dep_stat.reset_index(inplace=True)\n",
    "print(user_dep_stat.columns)\n",
    "user_dep_stat.to_pickle(DATA_DIR + 'user_department_products.pkl')\n",
    "\n",
    "user_aisle_stat = orders_products_products.groupby(['user_id', 'aisle_id']).agg(\n",
    "    {'product_id': lambda x: x.nunique(),\n",
    "     'reordered': 'sum'\n",
    "     })\n",
    "print(user_aisle_stat.columns)\n",
    "user_aisle_stat.rename(columns={'product_id': 'aisle_products',\n",
    "                                'reordered': 'aisle_reordered'}, inplace=True)\n",
    "user_aisle_stat.reset_index(inplace=True)\n",
    "user_aisle_stat.to_pickle(DATA_DIR + 'user_aisle_products.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate prod2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_product = pd.merge(order_prior, orders, on='order_id')\n",
    "prod2vec = order_prior.sort_values(['order_id']).groupby('order_id')['product_id']\\\n",
    "    .apply(lambda x: x.tolist()).to_frame('products').reset_index()\n",
    "prod2vec = pd.merge(prod2vec, orders, on='order_id')\n",
    "prod2vec.to_pickle(os.path.join(DATA_DIR, 'prod2vec.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
